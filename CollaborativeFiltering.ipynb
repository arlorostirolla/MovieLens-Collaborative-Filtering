{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3xQa6VlNAOe"
   },
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "0mG3n0qRNTSA",
    "outputId": "cb0eadbd-b8a8-41b1-e3b4-7f44b47a8804"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "0      196      242       3  881250949\n",
       "1      186      302       3  891717742\n",
       "2       22      377       1  878887116\n",
       "3      244       51       2  880606923\n",
       "4      166      346       1  886397596"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load MovieLens 100K dataset into a dataframe of pandas\n",
    "names = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "df = pd.read_csv('u.data', sep='\\t', names=names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hFJT0QWudp1P"
   },
   "outputs": [],
   "source": [
    "# Select 500 most active users and 500 most active items from the dataset\n",
    "n_most_active_users = 500\n",
    "n_most_active_items = 500\n",
    "\n",
    "user_ids = df.groupby('user_id').count().sort_values(by='rating', ascending=False).head(n_most_active_users).index\n",
    "item_ids = df.groupby('item_id').count().sort_values(by='rating', ascending=False).head(n_most_active_items).index\n",
    "df = df[(df['user_id'].isin(user_ids)) & (df['item_id'].isin(item_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "r012fu0jJkJc"
   },
   "outputs": [],
   "source": [
    "# Map new internal ID for items\n",
    "i_ids = df['item_id'].unique().tolist()\n",
    "item_dict = dict(zip(i_ids, [i for i in range(len(i_ids))]))\n",
    "df['item_id'] = df['item_id'].map(item_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ3rlC7jO6WJ"
   },
   "source": [
    "# Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EwS00lvHO-ca",
    "outputId": "f9f3a031-b4e7-439e-c3e3-c165b2286d19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-fb140fbf3b12>:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
      "<ipython-input-4-fb140fbf3b12>:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n"
     ]
    }
   ],
   "source": [
    "# The number of training users and active users\n",
    "n_training_users = 300\n",
    "n_active_users = n_most_active_users - n_training_users\n",
    "\n",
    "# The number of GIVEN ratings for active users\n",
    "GIVEN = 20\n",
    "\n",
    "# Randomly select users from the most active users as training set\n",
    "random_uids = np.random.choice(df.user_id.unique(), n_training_users, replace=False)\n",
    "train_df = df[df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all users in the training set\n",
    "u_ids = train_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "train_df['user_id'] = train_df['user_id'].map(user_dict)\n",
    "\n",
    "# The rest of users are active users for testing\n",
    "remain_df = df[~df['user_id'].isin(random_uids)]\n",
    "# Map new internal ID for all active users\n",
    "u_ids = remain_df['user_id'].unique().tolist()\n",
    "user_dict = dict(zip(u_ids, [i for i in range(len(u_ids))]))\n",
    "remain_df['user_id'] = remain_df['user_id'].map(user_dict)\n",
    "\n",
    "# Randomly select GIVEN ratings for active users\n",
    "active_df = remain_df.groupby('user_id').sample(n=GIVEN, random_state=1024)\n",
    "\n",
    "test_df = remain_df[~remain_df.index.isin(active_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-ke62G3jiYb",
    "outputId": "1c135984-edb4-4f2b-fc73-9225d86a0c38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        3.0  0.0  0.0  0.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  2.0  0.0  4.0  0.0  4.0  4.0  0.0  0.0  2.0  ...  0.0  4.0  4.0   \n",
       " 2        0.0  0.0  4.0  4.0  4.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 3        4.0  0.0  5.0  0.0  1.0  0.0  3.0  2.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 4        0.0  4.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  4.0  ...  0.0  0.0  3.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 295      4.0  0.0  3.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 296      0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 297      0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  3.0  4.0  0.0   \n",
       " 298      0.0  0.0  0.0  3.0  0.0  0.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  5.0   \n",
       " 299      0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  3.0  0.0  ...  4.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  4.0  0.0  3.0  0.0  \n",
       " 1        0.0  3.0  3.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        4.0  1.0  0.0  0.0  0.0  0.0  2.0  \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 295      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 296      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 297      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 298      0.0  0.0  3.0  0.0  0.0  0.0  0.0  \n",
       " 299      5.0  0.0  0.0  3.0  0.0  0.0  0.0  \n",
       " \n",
       " [300 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        4.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 2        4.0  0.0  0.0  0.0  0.0  3.0  4.0  2.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  5.0  ...  0.0  0.0  0.0   \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  0.0  0.0  0.0  0.0  2.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 197      0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns],\n",
       " item_id  0    1    2    3    4    5    6    7    8    9    ...  490  491  492  \\\n",
       " user_id                                                    ...                  \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 1        0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  4.0  ...  0.0  0.0  0.0   \n",
       " 2        0.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0  0.0  2.0  ...  0.0  2.0  0.0   \n",
       " 3        3.0  0.0  4.0  0.0  0.0  3.0  0.0  2.0  0.0  0.0  ...  0.0  4.0  0.0   \n",
       " 4        0.0  0.0  0.0  0.0  5.0  5.0  0.0  3.0  5.0  0.0  ...  0.0  4.0  0.0   \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       " 195      0.0  0.0  5.0  0.0  5.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 196      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  ...  0.0  0.0  0.0   \n",
       " 197      0.0  4.0  0.0  0.0  0.0  4.0  0.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 198      4.0  0.0  4.0  0.0  0.0  4.0  3.0  4.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       " 199      0.0  0.0  0.0  0.0  0.0  0.0  0.0  5.0  4.0  5.0  ...  0.0  0.0  4.0   \n",
       " \n",
       " item_id  493  494  495  496  497  498  499  \n",
       " user_id                                     \n",
       " 0        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 1        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 2        0.0  0.0  0.0  0.0  4.0  0.0  0.0  \n",
       " 3        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 4        0.0  0.0  0.0  3.0  0.0  3.0  0.0  \n",
       " ...      ...  ...  ...  ...  ...  ...  ...  \n",
       " 195      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 196      0.0  0.0  0.0  0.0  0.0  3.0  4.0  \n",
       " 197      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 198      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       " 199      0.0  4.0  2.0  3.0  0.0  0.0  0.0  \n",
       " \n",
       " [200 rows x 500 columns])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the format of datasets to matrices\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_training_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_training_users), 'rating': 0})\n",
    "train_ds = df_zeros.merge(train_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "df_zeros = pd.DataFrame({'user_id': np.tile(np.arange(0, n_active_users), n_most_active_items), 'item_id': np.repeat(np.arange(0, n_most_active_items), n_active_users), 'rating': 0})\n",
    "active_ds = df_zeros.merge(active_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "test_ds = df_zeros.merge(test_df, how='left', on=['user_id', 'item_id']).fillna(0.).pivot_table(values='rating_y', index='user_id', columns='item_id')\n",
    "\n",
    "train_ds, active_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yElYv2TDKKGu"
   },
   "outputs": [],
   "source": [
    "# Predicting All Missing Data in training set\n",
    "imputed_train_ds = train_ds.values.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iy4FurbHD4dt"
   },
   "source": [
    "# Your implementation to predict the missing values\n",
    "(Put all your implementation for your algorithm in the following cell only to handle the missing values; )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zYh1bVd0ncz3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user similarity matrix: 99.67% complete"
     ]
    }
   ],
   "source": [
    "## Put all your implementation for your solutioin in this cell only to predict the missing values; \n",
    "## NOTE 1: DO NOT change anything in the rest of the cells in this framework, \n",
    "## otherwise the changes might cause errors and make your implementation invalid.\n",
    "\n",
    "## Note 2: \n",
    "## The user-item rating matrix is imputed_train_ds, \n",
    "## and the missing values are those 0s in imputed_train_ds. \n",
    "## You are required to predict them by using the solution in the given report. \n",
    "\n",
    "## The following parameters are required in the given report, \n",
    "## which is named \"Effective Missing Data Prediction for Collaborative Filtering\", \n",
    "## and you will need to use them. But, please do not change their values. \n",
    "\n",
    "LAMBDA = 0.7    # λ\n",
    "GAMMA = 10      # γ\n",
    "DELTA = 10      # δ\n",
    "ETA = 0.7       # η\n",
    "THETA = 0.7     # θ\n",
    "EPSILON = 1e-9\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "# create data objects \n",
    "train_dataframe = pd.DataFrame(imputed_train_ds, copy=True)\n",
    "normalized_ratings_user = train_dataframe.copy()\n",
    "normalized_ratings_item = train_dataframe.copy()\n",
    "np_train = train_dataframe.to_numpy()\n",
    "\n",
    "# creates a binary dataframe by dividing values by themselves if above 0\n",
    "binary_train = train_dataframe.applymap(lambda x: x/x if x > 0 else x*x)\n",
    "\n",
    "# calculates average ratings\n",
    "user_average_rating = np_train.sum(axis=1)/binary_train.sum(axis=1)\n",
    "item_average_rating = np_train.sum(axis=0)/binary_train.sum(axis=0)\n",
    "\n",
    "# calculates weighted similarity rating\n",
    "def similarity_rating(x,y, constant, N):\n",
    "    top_sum = []\n",
    "    bottom_sum_i = []\n",
    "    bottom_sum_j = []\n",
    "    \n",
    "    # calculates common ratings\n",
    "    def shared_ratings(i, j, count=0):\n",
    "        if count == N:\n",
    "            return\n",
    "        elif i[count] != 0 and j[count] != 0:\n",
    "            sum_ij = i[count]*j[count]\n",
    "            top_sum.append(sum_ij)\n",
    "            bottom_sum_i.append(i[count])\n",
    "            bottom_sum_j.append(j[count])\n",
    "            shared_ratings(i,j, count=count+1)\n",
    "        else:\n",
    "            shared_ratings(i,j, count=count+1)\n",
    "        \n",
    "    shared_ratings(x, y)   \n",
    "    top_sum = sum(top_sum)\n",
    "    bottom_i = sqrt(sum([i**2 for i in bottom_sum_i]))\n",
    "    bottom_j = sqrt(sum([j**2 for j in bottom_sum_j]))\n",
    "    pearson = top_sum/(bottom_i * bottom_j + EPSILON)\n",
    "    return ((min(len(bottom_sum_i), constant))/constant) * pearson\n",
    "\n",
    "# normalize the data (value - mean)\n",
    "for i in range(300):\n",
    "    normalized_ratings_user.iloc[i] = normalized_ratings_user.iloc[i].apply(\n",
    "                                        lambda j: j-user_average_rating[i] if j>0 else j+0)\n",
    "\n",
    "for i in range(500):\n",
    "    normalized_ratings_item.iloc[:,i] = normalized_ratings_item.iloc[:,i].apply(\n",
    "                                        lambda x: x-item_average_rating[i] if i>0 else i+0)\n",
    "\n",
    "user_similarity_matrix = np.zeros((300,300))     \n",
    "item_similarity_matrix = np.zeros((500,500))\n",
    "\n",
    "# calculate and append item similarity score to item matrix\n",
    "for i in range(500):\n",
    "    print('\\ritem similarity matrix: ' + str(round((i/500)*100, 2)) +'% complete', end='')\n",
    "    for j in range(500):\n",
    "        if i == j:\n",
    "            pass\n",
    "        else:\n",
    "            item_similarity_matrix[i][j] = similarity_rating( \\\n",
    "                normalized_ratings_item.iloc[:,i], normalized_ratings_item.iloc[:,j], DELTA, 299)\n",
    "\n",
    "# calculate and append user similarity score to user matrix\n",
    "for i in range(300):\n",
    "    print('\\ruser similarity matrix: ' + str(round((i/300)*100, 2)) + '% complete', end='')\n",
    "    for j in range(300):\n",
    "        if i == j:\n",
    "            pass\n",
    "        else:\n",
    "            user_similarity_matrix[i][j] = similarity_rating( \\\n",
    "                normalized_ratings_user.iloc[i], normalized_ratings_user.iloc[j], GAMMA, 499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = pd.DataFrame(user_similarity_matrix)\n",
    "item_df = pd.DataFrame(item_similarity_matrix)\n",
    "\n",
    "# creates a nested dictionary of similar users given a single user (Sim > ETA)\n",
    "def similar_users(user):\n",
    "    sim_list = []\n",
    "    sim_index = []\n",
    "    mask = user_df.iloc[user]\n",
    "    for i in range(len(mask)):\n",
    "        if mask[i] > ETA:\n",
    "            sim_list.append(mask[i])\n",
    "            sim_index.append(i-1)\n",
    "        else:\n",
    "            pass\n",
    "    return dict(zip(sim_index, sim_list))\n",
    "\n",
    "# creates a nested dictionary of similar items given a single item (Sim > THETA)\n",
    "def similar_items(item):\n",
    "    item_list = []\n",
    "    item_index = []\n",
    "    mask = item_df.iloc[item]\n",
    "    \n",
    "    for i in range(len(mask)):\n",
    "        if mask[i] > THETA:\n",
    "            item_list.append(mask[i])\n",
    "            item_index.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    return dict(zip(item_index, item_list))\n",
    "\n",
    "sim_user_dict = {}\n",
    "sim_item_dict = {}\n",
    "\n",
    "# these functions collate similar users/items into one nested dictionary\n",
    "for i in range(500):\n",
    "    sim_item_dict[i] = similar_items(i)\n",
    "\n",
    "for i in range(300):\n",
    "    sim_user_dict[i] = similar_users(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values prediction: 99.66666666666667% completeee"
     ]
    }
   ],
   "source": [
    "# function to process the whole dataframe\n",
    "def missing_values_prediction(data, out):\n",
    "    \n",
    "    # equation 9 from report\n",
    "    def only_users(user_index, item_index):\n",
    "        sum_similar_users = []\n",
    "        sum_sim_with_ratings = []\n",
    "        \n",
    "        for i in sim_user_dict[user_index].values():\n",
    "            sum_similar_users.append(i)\n",
    "        for key, value in sim_user_dict[user_index].items():\n",
    "            similarity = value\n",
    "            rating = data.iloc[key, item_index]\n",
    "            eq_top = similarity * rating\n",
    "            sum_sim_with_ratings.append(eq_top)\n",
    "        sum_similar_users = sum(sum_similar_users)+EPSILON\n",
    "        sum_sim_with_ratings = sum(sum_sim_with_ratings)\n",
    "        prediction =user_average_rating[user_index] + (sum_sim_with_ratings/sum_similar_users)\n",
    "        return prediction\n",
    "    \n",
    "    # equation 10 from report\n",
    "    def only_items(user_index, item_index):\n",
    "        sum_similar_items = []\n",
    "        sum_sim_plus_ratings = []\n",
    "    \n",
    "        for i in sim_item_dict[item_index].values():\n",
    "            sum_similar_items.append(i)\n",
    "            \n",
    "        for key, value in sim_item_dict[item_index].items():\n",
    "            similarity = value\n",
    "            rating = data.iloc[user_index, key]\n",
    "            eq_top = similarity * rating\n",
    "            sum_sim_plus_ratings.append(eq_top)\n",
    "        \n",
    "        \n",
    "        sum_similar_items = sum(sum_similar_items)+EPSILON\n",
    "        sum_sim_plus_ratings = sum(sum_sim_plus_ratings)\n",
    "        prediction = item_average_rating[item_index] + (sum_sim_plus_ratings/sum_similar_items)\n",
    "        return prediction\n",
    "   \n",
    "    # equation 11 from report\n",
    "    def null_users_items(user_index, item_index):\n",
    "        prediction = 0\n",
    "        return prediction\n",
    "    \n",
    "    # equation 8 from report\n",
    "    def users_and_items(user_index, item_index):\n",
    "        prediction = (LAMBDA * only_users(user_index, item_index))+ \\\n",
    "                     ((1-LAMBDA)*only_items(user_index, item_index))\n",
    "        return prediction\n",
    "    \n",
    "    # tests whether similar users/items exist for a given user/item, and directs to the appropriate\n",
    "    # function from the report\n",
    "    for user in range(300):\n",
    "        print('\\rMissing values prediction: '+str((user/300)*100)+'% complete', end='')\n",
    "        for item in range(500):\n",
    "            if data.iloc[user][item] == 0:\n",
    "                if not any(sim_user_dict[user].values()) and not any(sim_item_dict[item].values()):\n",
    "                    out[user][item] = null_users_items(user, item)\n",
    "                elif any(sim_user_dict[user].values()) and not any(sim_item_dict.values()):\n",
    "                    out[user][item] =  only_users(user, item)\n",
    "                elif not any(sim_user_dict[user].values()) and any(sim_item_dict.values()):\n",
    "                    out[user][item] = only_items(user, item)\n",
    "                elif any(sim_user_dict[user].values()) and any(sim_item_dict.values()):\n",
    "                    out[user][item] = users_and_items(user, item)\n",
    "                    \n",
    "temp = imputed_train_ds.copy()\n",
    "missing_values_prediction(normalized_ratings_user, temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_train_ds = temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GbOfVWTV_Aij"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Txs8YjwTzuSP"
   },
   "outputs": [],
   "source": [
    "### Compute Pearson Correlation Coefficient of All Pairs of Items between active set and imputed training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "KoOgX_axKKGw",
    "outputId": "37a7adbd-e0d6-4375-e28c-3940977896f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.639611</td>\n",
       "      <td>4.257986</td>\n",
       "      <td>3.910932</td>\n",
       "      <td>3.479410</td>\n",
       "      <td>3.255197</td>\n",
       "      <td>3.898395</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.992069</td>\n",
       "      <td>3.648810</td>\n",
       "      <td>...</td>\n",
       "      <td>2.991577</td>\n",
       "      <td>2.833558</td>\n",
       "      <td>3.852707</td>\n",
       "      <td>3.838886</td>\n",
       "      <td>2.942275</td>\n",
       "      <td>2.229971</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.587126</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.291771</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.426439</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.644236</td>\n",
       "      <td>2.950128</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.937255</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.816170</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.995041</td>\n",
       "      <td>3.549562</td>\n",
       "      <td>2.839290</td>\n",
       "      <td>3.032040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.614951</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.194995</td>\n",
       "      <td>3.877520</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.949898</td>\n",
       "      <td>3.648810</td>\n",
       "      <td>...</td>\n",
       "      <td>2.958499</td>\n",
       "      <td>2.817640</td>\n",
       "      <td>3.814100</td>\n",
       "      <td>3.811413</td>\n",
       "      <td>2.901022</td>\n",
       "      <td>2.202534</td>\n",
       "      <td>2.003759</td>\n",
       "      <td>3.554014</td>\n",
       "      <td>2.842264</td>\n",
       "      <td>3.041962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.635358</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.838011</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.221615</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.963678</td>\n",
       "      <td>3.648810</td>\n",
       "      <td>...</td>\n",
       "      <td>2.983132</td>\n",
       "      <td>2.839243</td>\n",
       "      <td>3.831660</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.229155</td>\n",
       "      <td>2.024312</td>\n",
       "      <td>3.580671</td>\n",
       "      <td>2.860346</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.536224</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.470153</td>\n",
       "      <td>3.374718</td>\n",
       "      <td>3.241624</td>\n",
       "      <td>3.170208</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.323983</td>\n",
       "      <td>3.092923</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.093887</td>\n",
       "      <td>3.047369</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.347975</td>\n",
       "      <td>3.079818</td>\n",
       "      <td>2.866614</td>\n",
       "      <td>1.485390</td>\n",
       "      <td>3.272267</td>\n",
       "      <td>3.058809</td>\n",
       "      <td>3.118162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.606571</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.813877</td>\n",
       "      <td>3.446690</td>\n",
       "      <td>3.213078</td>\n",
       "      <td>3.864868</td>\n",
       "      <td>3.749184</td>\n",
       "      <td>2.964268</td>\n",
       "      <td>3.648810</td>\n",
       "      <td>...</td>\n",
       "      <td>2.952859</td>\n",
       "      <td>2.805321</td>\n",
       "      <td>3.818406</td>\n",
       "      <td>3.813969</td>\n",
       "      <td>2.909498</td>\n",
       "      <td>2.203368</td>\n",
       "      <td>2.011432</td>\n",
       "      <td>3.557402</td>\n",
       "      <td>2.845739</td>\n",
       "      <td>3.042909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>5.270532</td>\n",
       "      <td>4.116984</td>\n",
       "      <td>3.898335</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.069801</td>\n",
       "      <td>4.000024</td>\n",
       "      <td>4.486027</td>\n",
       "      <td>4.436320</td>\n",
       "      <td>2.809660</td>\n",
       "      <td>4.413562</td>\n",
       "      <td>...</td>\n",
       "      <td>3.920834</td>\n",
       "      <td>2.764884</td>\n",
       "      <td>4.179491</td>\n",
       "      <td>4.464349</td>\n",
       "      <td>3.906006</td>\n",
       "      <td>3.693157</td>\n",
       "      <td>3.635500</td>\n",
       "      <td>4.099650</td>\n",
       "      <td>3.885441</td>\n",
       "      <td>3.945770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>5.017522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.733663</td>\n",
       "      <td>3.588184</td>\n",
       "      <td>3.489985</td>\n",
       "      <td>3.406959</td>\n",
       "      <td>3.618718</td>\n",
       "      <td>3.555579</td>\n",
       "      <td>3.345780</td>\n",
       "      <td>3.560552</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.605800</td>\n",
       "      <td>3.602849</td>\n",
       "      <td>3.334318</td>\n",
       "      <td>3.120168</td>\n",
       "      <td>3.062121</td>\n",
       "      <td>3.525856</td>\n",
       "      <td>3.311995</td>\n",
       "      <td>3.373172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.626030</td>\n",
       "      <td>4.263028</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.462226</td>\n",
       "      <td>3.232139</td>\n",
       "      <td>3.904725</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.984710</td>\n",
       "      <td>3.648810</td>\n",
       "      <td>...</td>\n",
       "      <td>2.980021</td>\n",
       "      <td>2.832778</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.834968</td>\n",
       "      <td>2.938525</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.041199</td>\n",
       "      <td>3.583167</td>\n",
       "      <td>2.868084</td>\n",
       "      <td>3.062397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>3.820762</td>\n",
       "      <td>3.655993</td>\n",
       "      <td>3.848230</td>\n",
       "      <td>4.075377</td>\n",
       "      <td>3.604843</td>\n",
       "      <td>3.532230</td>\n",
       "      <td>3.735458</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.135666</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.416307</td>\n",
       "      <td>4.023534</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.449939</td>\n",
       "      <td>2.705811</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.784704</td>\n",
       "      <td>3.568281</td>\n",
       "      <td>3.181124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    3.000000  3.639611  4.257986  3.910932  3.479410  3.255197  3.898395   \n",
       "1    0.000000  2.000000  4.291771  4.000000  3.426439  4.000000  4.000000   \n",
       "2    0.000000  3.614951  4.000000  4.000000  4.000000  3.194995  3.877520   \n",
       "3    4.000000  3.635358  5.000000  3.838011  1.000000  3.221615  3.000000   \n",
       "4    3.536224  4.000000  3.470153  3.374718  3.241624  3.170208  3.000000   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "295  4.000000  3.606571  3.000000  3.813877  3.446690  3.213078  3.864868   \n",
       "296  5.270532  4.116984  3.898335  5.000000  4.069801  4.000024  4.486027   \n",
       "297  5.017522  1.000000  3.733663  3.588184  3.489985  3.406959  3.618718   \n",
       "298  0.000000  3.626030  4.263028  3.000000  3.462226  3.232139  3.904725   \n",
       "299  3.820762  3.655993  3.848230  4.075377  3.604843  3.532230  3.735458   \n",
       "\n",
       "          7         8         9    ...       490       491       492  \\\n",
       "0    4.000000  2.992069  3.648810  ...  2.991577  2.833558  3.852707   \n",
       "1    3.644236  2.950128  2.000000  ...  2.937255  4.000000  4.000000   \n",
       "2    4.000000  2.949898  3.648810  ...  2.958499  2.817640  3.814100   \n",
       "3    2.000000  2.963678  3.648810  ...  2.983132  2.839243  3.831660   \n",
       "4    3.323983  3.092923  4.000000  ...  3.093887  3.047369  3.000000   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "295  3.749184  2.964268  3.648810  ...  2.952859  2.805321  3.818406   \n",
       "296  4.436320  2.809660  4.413562  ...  3.920834  2.764884  4.179491   \n",
       "297  3.555579  3.345780  3.560552  ...  3.000000  4.000000  3.605800   \n",
       "298  4.000000  2.984710  3.648810  ...  2.980021  2.832778  5.000000   \n",
       "299  3.000000  3.000000  4.135666  ...  4.000000  3.416307  4.023534   \n",
       "\n",
       "          493       494       495       496       497       498       499  \n",
       "0    3.838886  2.942275  2.229971  4.000000  3.587126  3.000000  3.068966  \n",
       "1    3.816170  3.000000  3.000000  1.995041  3.549562  2.839290  3.032040  \n",
       "2    3.811413  2.901022  2.202534  2.003759  3.554014  2.842264  3.041962  \n",
       "3    4.000000  1.000000  2.229155  2.024312  3.580671  2.860346  2.000000  \n",
       "4    3.347975  3.079818  2.866614  1.485390  3.272267  3.058809  3.118162  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "295  3.813969  2.909498  2.203368  2.011432  3.557402  2.845739  3.042909  \n",
       "296  4.464349  3.906006  3.693157  3.635500  4.099650  3.885441  3.945770  \n",
       "297  3.602849  3.334318  3.120168  3.062121  3.525856  3.311995  3.373172  \n",
       "298  3.834968  2.938525  3.000000  2.041199  3.583167  2.868084  3.062397  \n",
       "299  5.000000  3.449939  2.705811  3.000000  3.784704  3.568281  3.181124  \n",
       "\n",
       "[300 rows x 500 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_train_ds = pd.DataFrame(imputed_train_ds)\n",
    "imputed_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eq0uq1aHzu11",
    "outputId": "f6214a46-d63e-4fdc-e7dd-ccaed23b237d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.85407503e-02,  5.48653444e-01,  2.31528108e-01, ...,\n",
       "        -1.16951931e-04,  4.83646295e-01,  3.03487967e-03],\n",
       "       [ 3.54593938e-01,  4.26647348e-02,  1.93358784e-01, ...,\n",
       "         2.19968261e-01,  1.22883012e-01,  2.49124791e-01],\n",
       "       [ 1.94995588e-01, -1.25920842e-01,  5.33115487e-02, ...,\n",
       "         2.32879460e-01, -2.11639808e-01,  1.47427713e-01],\n",
       "       ...,\n",
       "       [ 4.80077187e-01,  3.43105467e-01,  4.44370844e-01, ...,\n",
       "         1.18795451e-01, -1.71968431e-01,  3.36967369e-01],\n",
       "       [-1.87819414e-02,  2.34728614e-01, -2.54673693e-02, ...,\n",
       "         4.40982878e-01,  1.33216241e-01, -1.03795975e-01],\n",
       "       [ 4.00603733e-04,  4.43756620e-02, -4.39043896e-03, ...,\n",
       "         4.54009069e-02,  7.50890401e-02, -1.03179764e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_user_pearson_corr = np.zeros((active_ds.shape[0], train_ds.shape[0]))\n",
    "\n",
    "# Compute Pearson Correlation Coefficient of All Pairs of Users between active set and imputed training set\n",
    "for i, user_i_vec in enumerate(active_ds.values):\n",
    "    for j, user_j_vec in enumerate(imputed_train_ds.values):\n",
    "        \n",
    "        # ratings corated by the current pair od users\n",
    "        mask_i = user_i_vec > 0\n",
    "        mask_j = user_j_vec > 0\n",
    "\n",
    "        # corrated item index, skip if there are no corrated ratings\n",
    "        corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "        if len(corrated_index) == 0:\n",
    "            continue\n",
    "\n",
    "        # average value of user_i_vec and user_j_vec\n",
    "        mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "        mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "        # compute pearson corr\n",
    "        user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "        user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "        r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "        r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "        r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "        r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "        sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "\n",
    "        # significance weighting\n",
    "        weighted_sim = (min(len(corrated_index), GAMMA) / GAMMA) * sim\n",
    "\n",
    "        active_user_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "active_user_pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewTnN9kNb8Ys"
   },
   "source": [
    "## Predict Ratings of Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4ERndYXb8Ys",
    "outputId": "12607670-af61-403a-e4ce-f5e874bf8386"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 3.79586573, ..., 3.09264072, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 3.57396318, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [4.13264344, 0.        , 4.10833994, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 10\n",
    "\n",
    "test_ds_pred = np.zeros_like(test_ds.values)\n",
    "\n",
    "for (i, j), rating in np.ndenumerate(test_ds.values):\n",
    "\n",
    "    if rating > 0:\n",
    "\n",
    "        sim_user_ids = np.argsort(active_user_pearson_corr[i])[-1:-(K + 1):-1]\n",
    "\n",
    "        #==================user-based==================#\n",
    "        # the coefficient values of similar users\n",
    "        sim_val = active_user_pearson_corr[i][sim_user_ids]\n",
    "\n",
    "        # the average value of the current user's ratings\n",
    "        sim_users = imputed_train_ds.values[sim_user_ids]\n",
    "        user_mean = np.sum(active_ds.values[i]) / (np.sum(np.clip(active_ds.values[i], 0, 1)) + EPSILON)\n",
    "        sim_user_mean = np.sum(sim_users, axis=1) / (np.sum(np.clip(sim_users, 0, 1), axis=1) + EPSILON)\n",
    "\n",
    "        # select the users who rated item j\n",
    "        mask_rated_j = sim_users[:, j] > 0\n",
    "        \n",
    "        # sim(u, v) * (r_vj - mean_v)\n",
    "        sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "        \n",
    "        user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "        user_based_pred = np.clip(user_based_pred, 0, 5)\n",
    "\n",
    "        test_ds_pred[i][j] = user_based_pred\n",
    "        \n",
    "test_ds_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUTn4kSFb8ZA"
   },
   "source": [
    "## Compute MAE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7JCVmexyb8ZA",
    "outputId": "6f650170-e9a6-482a-b695-5fa474d964b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7456084428528457, RMSE: 0.9638337252408127\n"
     ]
    }
   ],
   "source": [
    "# MAE\n",
    "MAE = np.sum(np.abs(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1))\n",
    "\n",
    "# RMSE\n",
    "RMSE = np.sqrt(np.sum(np.square(test_ds_pred - test_ds.values)) / np.sum(np.clip(test_ds.values, 0, 1)))\n",
    "\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE, RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment3_framework.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
